{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: requests in /Users/kolawole/opt/anaconda3/envs/pythonenv/lib/python3.11/site-packages (2.31.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/kolawole/opt/anaconda3/envs/pythonenv/lib/python3.11/site-packages (from requests) (3.1.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/kolawole/opt/anaconda3/envs/pythonenv/lib/python3.11/site-packages (from requests) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/kolawole/opt/anaconda3/envs/pythonenv/lib/python3.11/site-packages (from requests) (1.26.16)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/kolawole/opt/anaconda3/envs/pythonenv/lib/python3.11/site-packages (from requests) (2023.7.22)\n",
      "Requirement already satisfied: pandas in /Users/kolawole/opt/anaconda3/envs/pythonenv/lib/python3.11/site-packages (2.0.3)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /Users/kolawole/opt/anaconda3/envs/pythonenv/lib/python3.11/site-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Users/kolawole/opt/anaconda3/envs/pythonenv/lib/python3.11/site-packages (from pandas) (2023.3)\n",
      "Requirement already satisfied: tzdata>=2022.1 in /Users/kolawole/opt/anaconda3/envs/pythonenv/lib/python3.11/site-packages (from pandas) (2023.3)\n",
      "Requirement already satisfied: numpy>=1.21.0 in /Users/kolawole/opt/anaconda3/envs/pythonenv/lib/python3.11/site-packages (from pandas) (1.25.1)\n",
      "Requirement already satisfied: six>=1.5 in /Users/kolawole/opt/anaconda3/envs/pythonenv/lib/python3.11/site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n"
     ]
    }
   ],
   "source": [
    "#Install Required Packages\n",
    "!pip install requests\n",
    "!pip install pandas\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Run re required packages\n",
    "import requests\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BUS DELAY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Count of new data: 611788\n"
     ]
    }
   ],
   "source": [
    "# Toronto Open Data is stored in a CKAN instance. Its APIs are documented here:\n",
    "# https://docs.ckan.org/en/latest/api/\n",
    "\n",
    "# To hit our API, you'll be making requests to:\n",
    "base_url = \"https://ckan0.cf.opendata.inter.prod-toronto.ca\"\n",
    "\n",
    "# Datasets are called \"packages\". Each package can contain many \"resources\".\n",
    "# To retrieve the metadata for this package and its resources, use the package name in this page's URL:\n",
    "url = base_url + \"/api/3/action/package_show\"\n",
    "params = {\"id\": \"ttc-bus-delay-data\"}\n",
    "package = requests.get(url, params=params).json()\n",
    "\n",
    "# Create an empty DataFrame to store the data\n",
    "final_df = pd.DataFrame()\n",
    "\n",
    "# To get resource data:\n",
    "for idx, resource in enumerate(package[\"result\"][\"resources\"]):\n",
    "\n",
    "    # To get metadata for non datastore_active resources:\n",
    "    if not resource[\"datastore_active\"]:\n",
    "        url = base_url + \"/api/3/action/resource_show?id=\" + resource[\"id\"]\n",
    "        resource_metadata = requests.get(url).json()\n",
    "\n",
    "        # From here, you can use the \"url\" attribute to download this file\n",
    "        download_url = resource_metadata[\"result\"][\"url\"]\n",
    "\n",
    "        # Exclude the specified file\n",
    "        if download_url == \"https://ckan0.cf.opendata.inter.prod-toronto.ca/dataset/e271cdae-8788-4980-96ce-6a5c95bc6618/resource/71bb1283-7388-4d23-aa4e-0f393a80abce/download/ttc-bus-delay-data-readme.xlsx\":\n",
    "            continue\n",
    "\n",
    "        # Download the data from the resource\n",
    "        try:\n",
    "            dfs = pd.read_excel(download_url, sheet_name=None)\n",
    "            # Concatenate all DataFrames from different sheets into a single DataFrame\n",
    "            for sheet_name, df in dfs.items():\n",
    "                # Append the new data to the final DataFrame\n",
    "                final_df = pd.concat([final_df, df], ignore_index=True)\n",
    "        except Exception as e:\n",
    "            print(f\"Error fetching data from {download_url}: {e}\")\n",
    "            continue\n",
    "\n",
    "# Get the count of new data rows\n",
    "new_data_count = len(final_df)\n",
    "\n",
    "#Since data was concatenated, some columns didn't match. We fix them here\n",
    "final_df['Date'] = final_df['Date'].fillna(final_df['Report Date'])\n",
    "final_df['Line'] = final_df['Line'].fillna(final_df['Route'])\n",
    "final_df['Delay'] = final_df['Delay'].fillna(final_df['Min Delay'].combine_first(final_df[' Min Delay']))\n",
    "final_df['Gap'] = final_df['Gap'].fillna(final_df['Min Gap'])\n",
    "final_df['Bound'] = final_df['Bound'].fillna(final_df['Direction'])\n",
    "\n",
    "#Convert to String to Title case to correct how some values were captures\n",
    "final_df['Location'] = final_df['Location'].astype(str).apply(lambda x: x.title())\n",
    "\n",
    "# Generate location to include City, Province, and Country - Needed to generate map coordinates\n",
    "final_df['Location Full'] = final_df['Location'] + \", Toronto, ON, CA\"\n",
    "\n",
    "# Drop the 'Report Date' column\n",
    "final_df.drop(columns=['Report Date', 'Route', 'Min Delay', 'Min Gap', ' Min Delay', 'Direction', 'Incident ID', 'Unnamed: 10'], inplace=True)\n",
    "\n",
    "# Save the final DataFrame as a CSV file\n",
    "final_df.to_csv(\"ttc_bus_delay_data.csv\", index=False)\n",
    "\n",
    "\n",
    "print(\"Count of new data:\", new_data_count)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# STREET CAR DELAY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Count of new data: 132280\n"
     ]
    }
   ],
   "source": [
    "# Toronto Open Data is stored in a CKAN instance. Its APIs are documented here:\n",
    "# https://docs.ckan.org/en/latest/api/\n",
    "\n",
    "# To hit our API, you'll be making requests to:\n",
    "base_url = \"https://ckan0.cf.opendata.inter.prod-toronto.ca\"\n",
    "\n",
    "# Datasets are called \"packages\". Each package can contain many \"resources\".\n",
    "# To retrieve the metadata for this package and its resources, use the package name in this page's URL:\n",
    "url = base_url + \"/api/3/action/package_show\"\n",
    "params = {\"id\": \"ttc-streetcar-delay-data\"}\n",
    "package = requests.get(url, params=params).json()\n",
    "\n",
    "# Create an empty DataFrame to store the data\n",
    "final_df = pd.DataFrame()\n",
    "\n",
    "# To get resource data:\n",
    "for idx, resource in enumerate(package[\"result\"][\"resources\"]):\n",
    "\n",
    "    # To get metadata for non datastore_active resources:\n",
    "    if not resource[\"datastore_active\"]:\n",
    "        url = base_url + \"/api/3/action/resource_show?id=\" + resource[\"id\"]\n",
    "        resource_metadata = requests.get(url).json()\n",
    "\n",
    "        # From here, you can use the \"url\" attribute to download this file\n",
    "        download_url = resource_metadata[\"result\"][\"url\"]\n",
    "\n",
    "        # Exclude the specified file\n",
    "        if download_url == \"https://ckan0.cf.opendata.inter.prod-toronto.ca/dataset/b68cb71b-44a7-4394-97e2-5d2f41462a5d/resource/0fe61851-c67b-49bc-8c27-3a89b33b43af/download/ttc-streetcar-delay-data-readme.xlsx\":\n",
    "            continue\n",
    "\n",
    "        # Download the data from the resource\n",
    "        try:\n",
    "            dfs = pd.read_excel(download_url, sheet_name=None)\n",
    "\n",
    "            # Concatenate all DataFrames from different sheets into a single DataFrame\n",
    "            for sheet_name, df in dfs.items():\n",
    "\n",
    "                # Append the new data to the final DataFrame\n",
    "                final_df = pd.concat([final_df, df], ignore_index=True)\n",
    "        except Exception as e:\n",
    "            print(f\"Error fetching data from {download_url}: {e}\")\n",
    "            continue\n",
    "\n",
    "# Get the count of new data rows\n",
    "new_data_count = len(final_df)\n",
    "\n",
    "# Fill up null Date fields with Report Date\n",
    "final_df['Date'] = final_df.apply(lambda row: row['Date'] if pd.notnull(row['Date']) else row['Report Date'], axis=1)\n",
    "final_df['Line'] = final_df.apply(lambda row: row['Line'] if pd.notnull(row['Line']) else row['Route'], axis=1)\n",
    "final_df['Delay'] = final_df.apply(lambda row: row['Delay'] if pd.notnull(row['Delay']) else row['Min Delay'], axis=1)\n",
    "final_df['Gap'] = final_df.apply(lambda row: row['Gap'] if pd.notnull(row['Gap']) else row['Min Gap'], axis=1)\n",
    "final_df['Bound'] = final_df.apply(lambda row: row['Bound'] if pd.notnull(row['Bound']) else row['Direction'], axis=1)\n",
    "\n",
    "#Convert column to to String and then Title case to correct how some values were captures\n",
    "final_df['Location'] = final_df['Location'].astype(str).apply(lambda x: x.title())\n",
    "\n",
    "# Generate location to include City, Province, and Country - Needed to generate map coordinates\n",
    "final_df['Location Full'] = final_df['Location'] + \", Toronto, ON, CA\"\n",
    "\n",
    "# Drop the 'Report Date' column\n",
    "final_df.drop(columns=['Report Date', 'Route', 'Min Delay', 'Min Gap', 'Direction', 'Incident ID'], inplace=True)\n",
    "\n",
    "# Save the final DataFrame as a CSV file\n",
    "final_df.to_csv(\"ttc_streetcar_delay_data.csv\", index=False)\n",
    "\n",
    "print(\"Count of new data:\", new_data_count)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SUBWAY DELAY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Count of new data: 184485\n"
     ]
    }
   ],
   "source": [
    "# Toronto Open Data is stored in a CKAN instance. Its APIs are documented here:\n",
    "# https://docs.ckan.org/en/latest/api/\n",
    "\n",
    "# To hit our API, you'll be making requests to:\n",
    "base_url = \"https://ckan0.cf.opendata.inter.prod-toronto.ca\"\n",
    "\n",
    "# Datasets are called \"packages\". Each package can contain many \"resources\".\n",
    "# To retrieve the metadata for this package and its resources, use the package name in this page's URL:\n",
    "url = base_url + \"/api/3/action/package_show\"\n",
    "params = {\"id\": \"ttc-subway-delay-data\"}\n",
    "package = requests.get(url, params=params).json()\n",
    "\n",
    "# Create an empty DataFrame to store the data\n",
    "final_df = pd.DataFrame()\n",
    "\n",
    "# To get resource data:\n",
    "for idx, resource in enumerate(package[\"result\"][\"resources\"]):\n",
    "\n",
    "    # To get metadata for non datastore_active resources:\n",
    "    if not resource[\"datastore_active\"]:\n",
    "        url = base_url + \"/api/3/action/resource_show?id=\" + resource[\"id\"]\n",
    "        resource_metadata = requests.get(url).json()\n",
    "\n",
    "        # From here, you can use the \"url\" attribute to download this file\n",
    "        download_url = resource_metadata[\"result\"][\"url\"]\n",
    "\n",
    "        # Exclude the specified file\n",
    "        if download_url == \"https://ckan0.cf.opendata.inter.prod-toronto.ca/dataset/996cfe8d-fb35-40ce-b569-698d51fc683b/resource/3900e649-f31e-4b79-9f20-4731bbfd94f7/download/ttc-subway-delay-codes.xlsx\":\n",
    "            continue\n",
    "        if download_url == \"https://ckan0.cf.opendata.inter.prod-toronto.ca/dataset/996cfe8d-fb35-40ce-b569-698d51fc683b/resource/ca43ac3d-3940-4315-889b-a9375e7b8aa4/download/ttc-subway-delay-data-readme.xlsx\":\n",
    "            continue\n",
    "        \n",
    "        # Download the data from the resource\n",
    "\n",
    "        # Download the data from the resource\n",
    "        try:\n",
    "            dfs = pd.read_excel(download_url, sheet_name=None)\n",
    "\n",
    "            # Concatenate all DataFrames from different sheets into a single DataFrame\n",
    "            for sheet_name, df in dfs.items():\n",
    "\n",
    "                # Append the new data to the final DataFrame\n",
    "                final_df = pd.concat([final_df, df], ignore_index=True)\n",
    "        except Exception as e:\n",
    "            print(f\"Error fetching data from {download_url}: {e}\")\n",
    "            continue\n",
    "\n",
    "# Get the count of new data rows\n",
    "new_data_count = len(final_df)\n",
    "\n",
    "# Delete the first 3 columns in the final DataFrame - NOT RELEVANT TO ME\n",
    "final_df = final_df.drop(columns=final_df.columns[:3])\n",
    "\n",
    "# Delete rows 2 to 10 in the final DataFrame - NOT RELEVANT TO ME.\n",
    "final_df = final_df.drop(final_df.index[0:10])\n",
    "\n",
    "#Convert to String to Title case to correct how some values were captures\n",
    "final_df['Location'] = final_df['Station'].astype(str).apply(lambda x: x.title())\n",
    "\n",
    "# Generate location to include City, Province, and Country - Needed to generate map coordinates\n",
    "final_df['Location Full'] = final_df['Location'] + \", Toronto, ON, CA\"\n",
    "\n",
    "# Drop the 'Station' column\n",
    "final_df.drop(columns=['Station'], inplace=True)\n",
    "\n",
    "\n",
    "# Save the final DataFrame as a CSV file\n",
    "final_df.to_csv(\"ttc_subway_delay_data.csv\", index=False)\n",
    "\n",
    "print(\"Count of new data:\", new_data_count)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pythonenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
